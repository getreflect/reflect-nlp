TOKENIZER_VOCAB_SIZE:  1000
SEQUENCE_MAX_LENGTH: 35
BATCH_SIZE: 128
NUM_EPOCHS: 20
TRAIN_TEST_SPLIT: 0.2
VALIDATION_SPLIT: 0.2
TAIL_SIZE: 10

# augmentation
## sentence variations
AUG:
  SENTENCE_VAR:
    TOTAL: 100
    VARS_PER: 3
    MUTATION_PROB: 0.1
  SENTENCE_NEG:
    TOTAL: 100
  SHUFFLE:
    TOTAL: 100
  GARBAGE:
    TOTAL: 100
    LENGTH_LOWER_BOUND: 1
    LENGTH_UPPER_BOUND: 10
  VOCAB_GARBAGE:
    TOTAL: 50
    TOPK: 50