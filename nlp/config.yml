TOKENIZER_VOCAB_SIZE:  1000
SEQUENCE_MAX_LENGTH: 75
BATCH_SIZE: 64
NUM_EPOCHS: 15
TRAIN_TEST_SPLIT: 0.25
VALIDATION_SPLIT: 0.1
TAIL_SIZE: 10

# augmentation
## sentence variations
AUG:
  SENTENCE_VAR:
    TOTAL: 200
    VARS_PER: 3
    MUTATION_PROB: 0.1
  SENTENCE_NEG:
    TOTAL: 150
  SHUFFLE:
    TOTAL: 50
  GARBAGE:
    TOTAL: 50
    LENGTH_LOWER_BOUND: 2
    LENGTH_UPPER_BOUND: 10
  VOCAB_GARBAGE:
    TOTAL: 100
    TOPK: 50